SNEIT: Salient Named Entity Identification in Tweets
-----------------------------------------------------
This paper proposes a novel solution to the problem of identifying Salient Named Entities (SNEs) from a tweet. SNEs are a subset of named entities identified from a tweet, that are central to a tweet's content and capture the tweet author's intention. Automatic identification of SNEs can aid several Information Retrieval tasks including filtering, clustering, user modeling, trend prediction and content analysis. The problem is challenging due to the  subjective nature of the SNEs and the unique characteristics of the tweet text. In this paper, we propose a two-phased approach to identify the SNEs. Firstly, we identify salient mentions in a tweet using an unsupervised algorithm. Secondly, a supervised classifier, built using a robust set of features, is used to disambiguate and link salient mention to a Knowledge Base
entry. We show that our method gives 12% higher precision compared to the baseline method. This performance is consistent when evaluated on a standard dataset for filtering task, with tweets spanning across four domains. We demonstrate that a dataset created by our method can scale up
well. We also make the human-annotated dataset we created for our experiments, publicly available to the research community.

Folder Structure
-------------------
Datasets - Contains the different datasets created and used in the paper. 
Java - Contains all the system utilities coded in Java.
Python - Contains all the system utilities coded in Python.

Compiling the code:
------------------------
1. Mongo : Download the Datasets in this package. Setup mongodb with this using TweetIndexer class in Java.
2. twitter4j.properties : Populate this file with twitter API credentials and place in the execution directory
3. Variables : The path to all the dataset , db, server and APIs should be populated here.

How to run this code:
-----------------------
PREPROCESSING: Creates page rank vector
> python preprocess.py <page rank node repetition factor> <Cognos topic>

Sample Usage :-
python preprocess.py 2 "mit" > ../Pagerank/mit.pgrk


EVALUATION :
> java -jar ReplabData.jar <replab query>

Sample Usage :-
> java -jar ReplabData.jar "Ferrari"


SCALING :
1. Create page rank vector and tweets for SNEIT dataset
> python scaler.py <page rank node repetition factor> <Cognos topic>
2. Create SNIET dataset
> java -jar Scaler.jar <Cognos Topic> <Sne repetition factor> 

Sample Usage :-
> pythom scaler.py 2 "barclays" 
> java -jar Scaler.jar "barclays" "2"


EVALUATION of TSNE dataset :
>python TSNE_evaluate.py <number_of_tsne_rows>

Sample usage :
python TSNE_evaluate.py 10

This will randomly show TSNE dataset samples as 
<Tweet> -- [ranked list of SNEs]
For each sample, one can enter 1(SNE) or 0(NOT) and system outputs accuracy of TSNE dataset.

